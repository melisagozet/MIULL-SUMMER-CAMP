{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline_II.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End Diabetes Machine Learning Pipeline II"
      ],
      "metadata": {
        "id": "S7Vk4nfiMLrf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKIMt-9HLyqK"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "10qsLDVlMV6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing & Feature Engineering\n",
        "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
        "    \"\"\"\n",
        "\n",
        "    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
        "    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.\n",
        "\n",
        "    Parameters\n",
        "    ------\n",
        "        dataframe: dataframe\n",
        "                Değişken isimleri alınmak istenilen dataframe\n",
        "        cat_th: int, optional\n",
        "                numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n",
        "        car_th: int, optinal\n",
        "                kategorik fakat kardinal değişkenler için sınıf eşik değeri\n",
        "\n",
        "    Returns\n",
        "    ------\n",
        "        cat_cols: list\n",
        "                Kategorik değişken listesi\n",
        "        num_cols: list\n",
        "                Numerik değişken listesi\n",
        "        cat_but_car: list\n",
        "                Kategorik görünümlü kardinal değişken listesi\n",
        "\n",
        "    Examples\n",
        "    ------\n",
        "        import seaborn as sns\n",
        "        df = sns.load_dataset(\"iris\")\n",
        "        print(grab_col_names(df))\n",
        "\n",
        "\n",
        "    Notes\n",
        "    ------\n",
        "        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
        "        num_but_cat cat_cols'un içerisinde.\n",
        "        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # cat_cols, cat_but_car\n",
        "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
        "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
        "                   dataframe[col].dtypes != \"O\"]\n",
        "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
        "                   dataframe[col].dtypes == \"O\"]\n",
        "    cat_cols = cat_cols + num_but_cat\n",
        "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
        "\n",
        "    # num_cols\n",
        "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
        "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
        "\n",
        "    # print(f\"Observations: {dataframe.shape[0]}\")\n",
        "    # print(f\"Variables: {dataframe.shape[1]}\")\n",
        "    # print(f'cat_cols: {len(cat_cols)}')\n",
        "    # print(f'num_cols: {len(num_cols)}')\n",
        "    # print(f'cat_but_car: {len(cat_but_car)}')\n",
        "    # print(f'num_but_cat: {len(num_but_cat)}')\n",
        "    return cat_cols, num_cols, cat_but_car\n",
        "\n",
        "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
        "    quartile1 = dataframe[col_name].quantile(q1)\n",
        "    quartile3 = dataframe[col_name].quantile(q3)\n",
        "    interquantile_range = quartile3 - quartile1\n",
        "    up_limit = quartile3 + 1.5 * interquantile_range\n",
        "    low_limit = quartile1 - 1.5 * interquantile_range\n",
        "    return low_limit, up_limit\n",
        "\n",
        "def replace_with_thresholds(dataframe, variable):\n",
        "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
        "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
        "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
        "\n",
        "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
        "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
        "    return dataframe\n",
        "\n",
        "def diabetes_data_prep(dataframe):\n",
        "    dataframe.columns = [col.upper() for col in dataframe.columns]\n",
        "\n",
        "    # Glucose\n",
        "    dataframe['NEW_GLUCOSE_CAT'] = pd.cut(x=dataframe['GLUCOSE'], bins=[-1, 139, 200], labels=[\"normal\", \"prediabetes\"])\n",
        "\n",
        "    # Age\n",
        "    dataframe.loc[(dataframe['AGE'] < 35), \"NEW_AGE_CAT\"] = 'young'\n",
        "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55), \"NEW_AGE_CAT\"] = 'middleage'\n",
        "    dataframe.loc[(dataframe['AGE'] > 55), \"NEW_AGE_CAT\"] = 'old'\n",
        "\n",
        "    # BMI\n",
        "    dataframe['NEW_BMI_RANGE'] = pd.cut(x=dataframe['BMI'], bins=[-1, 18.5, 24.9, 29.9, 100],\n",
        "                                        labels=[\"underweight\", \"healty\", \"overweight\", \"obese\"])\n",
        "\n",
        "    # BloodPressure\n",
        "    dataframe['NEW_BLOODPRESSURE'] = pd.cut(x=dataframe['BLOODPRESSURE'], bins=[-1, 79, 89, 123],\n",
        "                                            labels=[\"normal\", \"hs1\", \"hs2\"])\n",
        "\n",
        "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe, cat_th=5, car_th=20)\n",
        "\n",
        "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
        "\n",
        "    df = one_hot_encoder(dataframe, cat_cols, drop_first=True)\n",
        "\n",
        "    cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)\n",
        "\n",
        "    replace_with_thresholds(df, \"INSULIN\")\n",
        "\n",
        "    X_scaled = StandardScaler().fit_transform(df[num_cols])\n",
        "    df[num_cols] = pd.DataFrame(X_scaled, columns=df[num_cols].columns)\n",
        "\n",
        "    y = df[\"OUTCOME\"]\n",
        "    X = df.drop([\"OUTCOME\"], axis=1)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Base Models\n",
        "def base_models(X, y, scoring=\"roc_auc\"):\n",
        "    print(\"Base Models....\")\n",
        "    classifiers = [('LR', LogisticRegression()),\n",
        "                   ('KNN', KNeighborsClassifier()),\n",
        "                   (\"SVC\", SVC()),\n",
        "                   (\"CART\", DecisionTreeClassifier()),\n",
        "                   (\"RF\", RandomForestClassifier()),\n",
        "                   ('Adaboost', AdaBoostClassifier()),\n",
        "                   ('GBM', GradientBoostingClassifier()),\n",
        "                   ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
        "                   ('LightGBM', LGBMClassifier()),\n",
        "                   # ('CatBoost', CatBoostClassifier(verbose=False))\n",
        "                   ]\n",
        "\n",
        "    for name, classifier in classifiers:\n",
        "        cv_results = cross_validate(classifier, X, y, cv=3, scoring=scoring)\n",
        "        print(f\"{scoring}: {round(cv_results['test_score'].mean(), 4)} ({name}) \")\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "\n",
        "# config.py\n",
        "\n",
        "knn_params = {\"n_neighbors\": range(2, 50)}\n",
        "\n",
        "cart_params = {'max_depth': range(1, 20),\n",
        "               \"min_samples_split\": range(2, 30)}\n",
        "\n",
        "rf_params = {\"max_depth\": [8, 15, None],\n",
        "             \"max_features\": [5, 7, \"auto\"],\n",
        "             \"min_samples_split\": [15, 20],\n",
        "             \"n_estimators\": [200, 300]}\n",
        "\n",
        "xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
        "                  \"max_depth\": [5, 8],\n",
        "                  \"n_estimators\": [100, 200],\n",
        "                  \"colsample_bytree\": [0.5, 1]}\n",
        "\n",
        "lightgbm_params = {\"learning_rate\": [0.01, 0.1],\n",
        "                   \"n_estimators\": [300, 500],\n",
        "                   \"colsample_bytree\": [0.7, 1]}\n",
        "\n",
        "classifiers = [('KNN', KNeighborsClassifier(), knn_params),\n",
        "               (\"CART\", DecisionTreeClassifier(), cart_params),\n",
        "               (\"RF\", RandomForestClassifier(), rf_params),\n",
        "               ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgboost_params),\n",
        "               ('LightGBM', LGBMClassifier(), lightgbm_params)]\n",
        "\n",
        "def hyperparameter_optimization(X, y, cv=3, scoring=\"roc_auc\"):\n",
        "    print(\"Hyperparameter Optimization....\")\n",
        "    best_models = {}\n",
        "    for name, classifier, params in classifiers:\n",
        "        print(f\"########## {name} ##########\")\n",
        "        cv_results = cross_validate(classifier, X, y, cv=cv, scoring=scoring)\n",
        "        print(f\"{scoring} (Before): {round(cv_results['test_score'].mean(), 4)}\")\n",
        "\n",
        "        gs_best = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, verbose=False).fit(X, y)\n",
        "        final_model = classifier.set_params(**gs_best.best_params_)\n",
        "\n",
        "        cv_results = cross_validate(final_model, X, y, cv=cv, scoring=scoring)\n",
        "        print(f\"{scoring} (After): {round(cv_results['test_score'].mean(), 4)}\")\n",
        "        print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n",
        "        best_models[name] = final_model\n",
        "    return best_models\n",
        "\n",
        "# Stacking & Ensemble Learning\n",
        "def voting_classifier(best_models, X, y):\n",
        "    print(\"Voting Classifier...\")\n",
        "    voting_clf = VotingClassifier(estimators=[('KNN', best_models[\"KNN\"]), ('RF', best_models[\"RF\"]),\n",
        "                                              ('LightGBM', best_models[\"LightGBM\"])],\n",
        "                                  voting='soft').fit(X, y)\n",
        "    cv_results = cross_validate(voting_clf, X, y, cv=3, scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n",
        "    print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\")\n",
        "    print(f\"F1Score: {cv_results['test_f1'].mean()}\")\n",
        "    print(f\"ROC_AUC: {cv_results['test_roc_auc'].mean()}\")\n",
        "    return voting_clf\n"
      ],
      "metadata": {
        "id": "kaw_1-HEMXA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1axQKVeM7r7",
        "outputId": "e2ed5e20-52e8-4798-f2bc-192af09de777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline Main Function\n",
        "################################################\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(\"/content/gdrive/My Drive/machine_learning/diabetes.csv\")\n",
        "    X, y = diabetes_data_prep(df)\n",
        "    base_models(X, y)\n",
        "    best_models = hyperparameter_optimization(X, y)\n",
        "    voting_clf = voting_classifier(best_models, X, y)\n",
        "    joblib.dump(voting_clf, \"voting_clf.pkl\")\n",
        "    return voting_clf\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"İşlem başladı\")\n",
        "    main()\n",
        "\n",
        "# git github\n",
        "# makefile (kod otamasyon aracı)\n",
        "# veri tabanlarından\n",
        "# log\n",
        "# class\n",
        "# docker\n",
        "# requirement.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3nS_SPMMyL8",
        "outputId": "ee053dc8-2ff7-44af-b43f-d69296a70d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "İşlem başladı\n",
            "Base Models....\n",
            "roc_auc: 0.8409 (LR) \n",
            "roc_auc: 0.791 (KNN) \n",
            "roc_auc: 0.8355 (SVC) \n",
            "roc_auc: 0.6481 (CART) \n",
            "roc_auc: 0.8254 (RF) \n",
            "roc_auc: 0.8196 (Adaboost) \n",
            "roc_auc: 0.8273 (GBM) \n",
            "roc_auc: 0.8309 (XGBoost) \n",
            "roc_auc: 0.8061 (LightGBM) \n",
            "Hyperparameter Optimization....\n",
            "########## KNN ##########\n",
            "roc_auc (Before): 0.791\n",
            "roc_auc (After): 0.8211\n",
            "KNN best params: {'n_neighbors': 20}\n",
            "\n",
            "########## CART ##########\n",
            "roc_auc (Before): 0.6312\n",
            "roc_auc (After): 0.7943\n",
            "CART best params: {'max_depth': 6, 'min_samples_split': 23}\n",
            "\n",
            "########## RF ##########\n",
            "roc_auc (Before): 0.8299\n",
            "roc_auc (After): 0.8367\n",
            "RF best params: {'max_depth': 15, 'max_features': 5, 'min_samples_split': 15, 'n_estimators': 300}\n",
            "\n",
            "########## XGBoost ##########\n",
            "roc_auc (Before): 0.8309\n",
            "roc_auc (After): 0.8241\n",
            "XGBoost best params: {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "\n",
            "########## LightGBM ##########\n",
            "roc_auc (Before): 0.8061\n",
            "roc_auc (After): 0.8259\n",
            "LightGBM best params: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'n_estimators': 300}\n",
            "\n",
            "Voting Classifier...\n",
            "Accuracy: 0.76953125\n",
            "F1Score: 0.6294673578243558\n",
            "ROC_AUC: 0.8379610107282689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline aşamaları\n",
        "1. İlk önce veriyi veritabanından çek\n",
        "2. Veriyi veri ön işleme skriptinden geçir. (dışarıdan çağır ya da bir skriptin içinde tutabilirsin)\n",
        "3. Genel modele bir bak -base model- (tercih sana kalmış)\n",
        "4. Hiperparametre optimizasyonu\n",
        "5. best_modeli kullanarak bir voting classifier oluştur. \n",
        "6. Model nesnesini bir yere kaydet (.pkl dump işlemi) training sürecini bir pipeline ile tamamlamış bulunuyoruz.\n",
        "\n",
        "komut satırından işletim sistemi seviyesinde kod çalıştırmak istersen bunu kullanmalısın  (kontrol mekanızmasıdır)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"İşlem başladı\") \n",
        "  #rapor, CLI ekleyebilirsin.\n",
        "    main() \n",
        "\n",
        "iki alttan çizgi : duble underscore\n",
        "iki alttan çizgi name : dandır name\n",
        "iki alttan çizgi main : dandır main"
      ],
      "metadata": {
        "id": "bAM-k6RMNWLR"
      }
    }
  ]
}